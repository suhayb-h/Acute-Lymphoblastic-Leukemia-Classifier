{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJuEP+a2y7IC7bnMeBf1Ad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhayb-h/Acute-Lymphoblastic-Leukemia-Classifier/blob/main/ARC1_download_data_CMNC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uy-Qy3jhnTNy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import imageio # replaces: from scipy.ndimage import imread"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#omniglot_url = 'http://github.com/brendenlake/omniglot/archive/master.zip'\n",
        "#data_dir = os.path.join(\"data\")\n",
        "#zip_location = os.path.join(data_dir, \"omniglot.zip\")\n",
        "#unzip_location = os.path.join(data_dir, \"extracted\")\n",
        "#zipped_images_location = os.path.join(unzip_location, \"omniglot-master\", \"python\")\n",
        "#extracted_images_location = os.path.join(data_dir, \"images\")\n",
        "\n",
        "\n",
        "#def download() -> None:\n",
        "#    if os.path.exists(zip_location) and os.path.isfile(zip_location):\n",
        "#        print(\"File {} already exists. Skipping download.\".format(zip_location))\n",
        "#        return\n",
        "#    print(\"Downloading the zip file from url {} and writing to {}\".format(\n",
        "#        omniglot_url, zip_location\n",
        "#    ))\n",
        "#    urllib.request.urlretrieve(omniglot_url, zip_location)\n",
        "#    print(\"Finished downloading.\")\n",
        "\n",
        "\n",
        "#def extract() -> None:\n",
        "#    print(\"Extracting {} to {}\".format(zip_location, unzip_location))\n",
        "#    zip_ref = zipfile.ZipFile(zip_location, 'r')\n",
        "#    zip_ref.extractall(unzip_location)\n",
        "#    zip_ref.close()\n",
        "#    print(\"Finished extracting.\")\n",
        "\n",
        "\n",
        "#def extract_images() -> None:\n",
        "#    image_sets = [\"images_background.zip\", \"images_evaluation.zip\"]\n",
        "#    image_sets = [os.path.join(zipped_images_location, image_set) for image_set in image_sets]\n",
        "#    print(\"Extracting image sets {}\".format(image_sets))\n",
        "\n",
        "#    for image_set in image_sets:\n",
        "#        zip_ref = zipfile.ZipFile(image_set, 'r')\n",
        "#        zip_ref.extractall(extracted_images_location)\n",
        "#        zip_ref.close()\n",
        "\n",
        "#    print(\"Done extracting image sets.\")\n",
        "\n",
        "\n",
        "def omniglot_folder_to_NDarray(path_im):\n",
        "    alphbts = os.listdir(path_im)\n",
        "    ALL_IMGS = []\n",
        "\n",
        "    for alphbt in alphbts:\n",
        "        chars = os.listdir(os.path.join(path_im, alphbt))\n",
        "        for char in chars:\n",
        "            img_filenames = os.listdir(os.path.join(path_im, alphbt, char))\n",
        "            char_imgs = []\n",
        "            for img_fn in img_filenames:\n",
        "                fn = os.path.join(path_im, alphbt, char, img_fn)\n",
        "                I = imageio.imread(fn) # updated with imageio\n",
        "                I = np.invert(I)\n",
        "                char_imgs.append(I)\n",
        "            ALL_IMGS.append(char_imgs)\n",
        "\n",
        "    return np.array(ALL_IMGS)\n",
        "\n",
        "\n",
        "def save_to_numpy() -> None:\n",
        "    image_folders = [\"images_background\", \"images_evaluation\"]\n",
        "    all_np_array = []\n",
        "    for image_folder in image_folders:\n",
        "        np_array_loc = os.path.join(data_dir, image_folder + \".npy\")\n",
        "        print(\"Converting folder {} to numpy array...\".format(image_folder))\n",
        "        np_array = omniglot_folder_to_NDarray(os.path.join(extracted_images_location, image_folder))\n",
        "        np.save(np_array_loc, np_array)\n",
        "        all_np_array.append(np_array)\n",
        "        print(\"Done.\")\n",
        "\n",
        "    all_np_array = np.concatenate(all_np_array, axis=0)\n",
        "    np.save(os.path.join(\"data\", \"omniglot.npy\"), all_np_array)\n",
        "\n",
        "\n",
        "def main():\n",
        "    download()\n",
        "    extract()\n",
        "    extract_images()\n",
        "    save_to_numpy()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "G_zAEYRMnUU4",
        "outputId": "658cb773-efeb-40dd-ef06-952135272fe1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the zip file from url http://github.com/brendenlake/omniglot/archive/master.zip and writing to data/omniglot.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-620ba667f91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-620ba667f91b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fc3b41a02e12>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0momniglot_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     ))\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momniglot_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished downloading.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# Handle temporary file setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/omniglot.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bs4Ua2V1PiEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}