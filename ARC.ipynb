{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hly8pkj6k_l11W8CfNSiwJZFyL-RYaKk",
      "authorship_tag": "ABX9TyPxgvTJeAUo5K32pAv/jej2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhayb-h/Acute-Lymphoblastic-Leukemia-Classifier/blob/main/ARC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import helper\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "import os\n",
        "import argparse\n",
        "from torch.autograd import Variable\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from numpy.random import choice\n",
        "from torch.autograd import Variable\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "import matplotlib as mpl\n",
        "import scipy\n",
        "from imageio import imread"
      ],
      "metadata": {
        "id": "gkww10zYZmdi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cD9uC6e_JTJ2"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "dataset = \\\n",
        "datasets.ImageFolder(\n",
        "    '/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/training_data', \n",
        "    transform=transform\n",
        "    )\n",
        "\n",
        "dataloader = \\\n",
        "torch.utils.data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size = 100, \n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "images, labels = next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[0].permute(1, 2, 0)).axes('off')\n",
        "#plt.imshow(images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "bjMvwLgLZiLh",
        "outputId": "4997da8c-b044-4f31-ca39-bcd51e984598"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4e4e9ec8418e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#plt.imshow(images[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not callable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"hem\",\n",
        "    1: \"all\"\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 2, 1\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
        "    img, label = dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze().permute(1,2))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Snx6gf7xJUFa",
        "outputId": "9c2fb286-fd03-422e-f1a0-89d0b2ee0bba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "taken and modified from https://github.com/pranv/ARC\n",
        "\"\"\"\n",
        "\n",
        "class Omniglot(object):\n",
        "    def __init__(self, path=os.path.join('data', 'omniglot.npy'), batch_size=128, image_size=32):\n",
        "        \"\"\"\n",
        "        batch_size: the output is (2 * batch size, 1, image_size, image_size)\n",
        "                    X[i] & X[i + batch_size] are the pair\n",
        "        image_size: size of the image\n",
        "        data_split: in number of alphabets, e.g. [30, 10] means out of 50 Omniglot characters,\n",
        "                    30 is for training, 10 for validation and the remaining(10) for testing\n",
        "        within_alphabet: for verfication task, when 2 characters are sampled to form a pair,\n",
        "                        this flag specifies if should they be from the same alphabet/language\n",
        "        ---------------------\n",
        "        Data Augmentation Parameters:\n",
        "            flip: here flipping both the images in a pair\n",
        "            scale: x would scale image by + or - x%\n",
        "            rotation_deg\n",
        "            shear_deg\n",
        "            translation_px: in both x and y directions\n",
        "        \"\"\"\n",
        "        chars = np.load(path)\n",
        "\n",
        "        # resize the images\n",
        "        resized_chars = np.zeros((1623, 20, image_size, image_size), dtype='uint8')\n",
        "        for i in range(1623):\n",
        "            for j in range(20):\n",
        "                resized_chars[i, j] = resize(chars[i, j], (image_size, image_size))\n",
        "        chars = resized_chars\n",
        "\n",
        "        self.mean_pixel = chars.mean() / 255.0  # used later for mean subtraction\n",
        "\n",
        "        # starting index of each alphabet in a list of chars\n",
        "        a_start = [0, 20, 49, 75, 116, 156, 180, 226, 240, 266, 300, 333, 355, 381,\n",
        "                   424, 448, 496, 518, 534, 586, 633, 673, 699, 739, 780, 813,\n",
        "                   827, 869, 892, 909, 964, 984, 1010, 1036, 1062, 1088, 1114,\n",
        "                   1159, 1204, 1245, 1271, 1318, 1358, 1388, 1433, 1479, 1507,\n",
        "                   1530, 1555, 1597]\n",
        "\n",
        "        # size of each alphabet (num of chars)\n",
        "        a_size = [20, 29, 26, 41, 40, 24, 46, 14, 26, 34, 33, 22, 26, 43, 24, 48, 22,\n",
        "                  16, 52, 47, 40, 26, 40, 41, 33, 14, 42, 23, 17, 55, 20, 26, 26, 26,\n",
        "                  26, 26, 45, 45, 41, 26, 47, 40, 30, 45, 46, 28, 23, 25, 42, 26]\n",
        "\n",
        "        # each alphabet/language has different number of characters.\n",
        "        # in order to uniformly sample all characters, we need weigh the probability\n",
        "        # of sampling a alphabet by its size. p is that probability\n",
        "        def size2p(size):\n",
        "            s = np.array(size).astype('float64')\n",
        "            return s / s.sum()\n",
        "\n",
        "        self.size2p = size2p\n",
        "\n",
        "        self.data = chars\n",
        "        self.a_start = a_start\n",
        "        self.a_size = a_size\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        flip = True\n",
        "        scale = 0.2\n",
        "        rotation_deg = 20\n",
        "        shear_deg = 10\n",
        "        translation_px = 5\n",
        "        self.augmentor = ImageAugmenter(image_size, image_size,\n",
        "                                        hflip=flip, vflip=flip,\n",
        "                                        scale_to_percent=1.0 + scale, rotation_deg=rotation_deg, shear_deg=shear_deg,\n",
        "                                        translation_x_px=translation_px, translation_y_px=translation_px)\n",
        "\n",
        "    def fetch_batch(self, part):\n",
        "        \"\"\"\n",
        "            This outputs batch_size number of pairs\n",
        "            Thus the actual number of images outputted is 2 * batch_size\n",
        "            Say A & B form the half of a pair\n",
        "            The Batch is divided into 4 parts:\n",
        "                Dissimilar A \t\tDissimilar B\n",
        "                Similar A \t\t\tSimilar B\n",
        "            Corresponding images in Similar A and Similar B form the similar pair\n",
        "            similarly, Dissimilar A and Dissimilar B form the dissimilar pair\n",
        "            When flattened, the batch has 4 parts with indices:\n",
        "                Dissimilar A \t\t0 - batch_size / 2\n",
        "                Similar A    \t\tbatch_size / 2  - batch_size\n",
        "                Dissimilar B \t\tbatch_size  - 3 * batch_size / 2\n",
        "                Similar B \t\t\t3 * batch_size / 2 - batch_size\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class Batcher(Omniglot):\n",
        "    def __init__(self, path=os.path.join('data', 'omniglot.npy'), batch_size=128, image_size=32):\n",
        "        Omniglot.__init__(self, path, batch_size, image_size)\n",
        "\n",
        "        a_start = self.a_start\n",
        "        a_size = self.a_size\n",
        "\n",
        "        # slicing indices for splitting a_start & a_size\n",
        "        i = 20\n",
        "        j = 30\n",
        "        starts = {}\n",
        "        starts['train'], starts['val'], starts['test'] = a_start[:i], a_start[i:j], a_start[j:]\n",
        "        sizes = {}\n",
        "        sizes['train'], sizes['val'], sizes['test'] = a_size[:i], a_size[i:j], a_size[j:]\n",
        "\n",
        "        size2p = self.size2p\n",
        "\n",
        "        p = {}\n",
        "        p['train'], p['val'], p['test'] = size2p(sizes['train']), size2p(sizes['val']), size2p(sizes['test'])\n",
        "\n",
        "        self.starts = starts\n",
        "        self.sizes = sizes\n",
        "        self.p = p\n",
        "\n",
        "    def fetch_batch(self, part, batch_size: int = None):\n",
        "\n",
        "        if batch_size is None:\n",
        "            batch_size = self.batch_size\n",
        "\n",
        "        X, Y = self._fetch_batch(part, batch_size)\n",
        "\n",
        "        X = Variable(torch.from_numpy(X)).view(2*batch_size, self.image_size, self.image_size)\n",
        "\n",
        "        X1 = X[:batch_size]  # (B, h, w)\n",
        "        X2 = X[batch_size:]  # (B, h, w)\n",
        "\n",
        "        X = torch.stack([X1, X2], dim=1)  # (B, 2, h, w)\n",
        "\n",
        "        Y = Variable(torch.from_numpy(Y))\n",
        "\n",
        "        if use_cuda:\n",
        "            X, Y = X.cuda(), Y.cuda()\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def _fetch_batch(self, part, batch_size: int = None):\n",
        "        if batch_size is None:\n",
        "            batch_size = self.batch_size\n",
        "\n",
        "        data = self.data\n",
        "        starts = self.starts[part]\n",
        "        sizes = self.sizes[part]\n",
        "        p = self.p[part]\n",
        "        image_size = self.image_size\n",
        "\n",
        "        num_alphbts = len(starts)\n",
        "\n",
        "        X = np.zeros((2 * batch_size, image_size, image_size), dtype='uint8')\n",
        "        for i in range(batch_size // 2):\n",
        "            # choose similar chars\n",
        "            same_idx = choice(range(starts[0], starts[-1] + sizes[-1]))\n",
        "\n",
        "            # choose dissimilar chars within alphabet\n",
        "            alphbt_idx = choice(num_alphbts, p=p)\n",
        "            char_offset = choice(sizes[alphbt_idx], 2, replace=False)\n",
        "            diff_idx = starts[alphbt_idx] + char_offset\n",
        "\n",
        "            X[i], X[i + batch_size] = data[diff_idx, choice(20, 2)]\n",
        "            X[i + batch_size // 2], X[i + 3 * batch_size // 2] = data[same_idx, choice(20, 2, replace=False)]\n",
        "\n",
        "        y = np.zeros((batch_size, 1), dtype='int32')\n",
        "        y[:batch_size // 2] = 0\n",
        "        y[batch_size // 2:] = 1\n",
        "\n",
        "        if part == 'train':\n",
        "            X = self.augmentor.augment_batch(X)\n",
        "        else:\n",
        "            X = X / 255.0\n",
        "\n",
        "        X = X - self.mean_pixel\n",
        "        X = X[:, np.newaxis]\n",
        "        X = X.astype(\"float32\")\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "6myA6uT5zfrJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "omniglot_url = 'http://github.com/brendenlake/omniglot/archive/master.zip'\n",
        "data_dir = os.path.join(\"data\")\n",
        "zip_location = os.path.join(data_dir, \"omniglot.zip\")\n",
        "unzip_location = os.path.join(data_dir, \"extracted\")\n",
        "zipped_images_location = os.path.join(unzip_location, \"omniglot-master\", \"python\")\n",
        "extracted_images_location = os.path.join(data_dir, \"images\")\n",
        "\n",
        "\n",
        "def download() -> None:\n",
        "    if os.path.exists(zip_location) and os.path.isfile(zip_location):\n",
        "        print(\"File {} already exists. Skipping download.\".format(zip_location))\n",
        "        return\n",
        "    print(\"Downloading the zip file from url {} and writing to {}\".format(\n",
        "        omniglot_url, zip_location\n",
        "    ))\n",
        "    urllib.request.urlretrieve(omniglot_url, zip_location)\n",
        "    print(\"Finished downloading.\")\n",
        "\n",
        "\n",
        "def extract() -> None:\n",
        "    print(\"Extracting {} to {}\".format(zip_location, unzip_location))\n",
        "    zip_ref = zipfile.ZipFile(zip_location, 'r')\n",
        "    zip_ref.extractall(unzip_location)\n",
        "    zip_ref.close()\n",
        "    print(\"Finished extracting.\")\n",
        "\n",
        "\n",
        "def extract_images() -> None:\n",
        "    image_sets = [\"images_background.zip\", \"images_evaluation.zip\"]\n",
        "    image_sets = [os.path.join(zipped_images_location, image_set) for image_set in image_sets]\n",
        "    print(\"Extracting image sets {}\".format(image_sets))\n",
        "\n",
        "    for image_set in image_sets:\n",
        "        zip_ref = zipfile.ZipFile(image_set, 'r')\n",
        "        zip_ref.extractall(extracted_images_location)\n",
        "        zip_ref.close()\n",
        "\n",
        "    print(\"Done extracting image sets.\")\n",
        "\n",
        "\n",
        "def omniglot_folder_to_NDarray(path_im):\n",
        "    alphbts = os.listdir(path_im)\n",
        "    ALL_IMGS = []\n",
        "\n",
        "    for alphbt in alphbts:\n",
        "        chars = os.listdir(os.path.join(path_im, alphbt))\n",
        "        for char in chars:\n",
        "            img_filenames = os.listdir(os.path.join(path_im, alphbt, char))\n",
        "            char_imgs = []\n",
        "            for img_fn in img_filenames:\n",
        "                fn = os.path.join(path_im, alphbt, char, img_fn)\n",
        "                I = imread(fn)\n",
        "                I = np.invert(I)\n",
        "                char_imgs.append(I)\n",
        "            ALL_IMGS.append(char_imgs)\n",
        "\n",
        "    return np.array(ALL_IMGS)\n",
        "\n",
        "\n",
        "def save_to_numpy() -> None:\n",
        "    image_folders = [\"images_background\", \"images_evaluation\"]\n",
        "    all_np_array = []\n",
        "    for image_folder in image_folders:\n",
        "        np_array_loc = os.path.join(data_dir, image_folder + \".npy\")\n",
        "        print(\"Converting folder {} to numpy array...\".format(image_folder))\n",
        "        np_array = omniglot_folder_to_NDarray(os.path.join(extracted_images_location, image_folder))\n",
        "        np.save(np_array_loc, np_array)\n",
        "        all_np_array.append(np_array)\n",
        "        print(\"Done.\")\n",
        "\n",
        "    all_np_array = np.concatenate(all_np_array, axis=0)\n",
        "    np.save(os.path.join(\"data\", \"omniglot.npy\"), all_np_array)\n",
        "\n",
        "\n",
        "def main():\n",
        "    download()\n",
        "    extract()\n",
        "    extract_images()\n",
        "    save_to_numpy()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_fKdgj6zpd7",
        "outputId": "864d34e3-de46-4c37-d9f8-6e773e477843"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File data/omniglot.zip already exists. Skipping download.\n",
            "Extracting data/omniglot.zip to data/extracted\n",
            "Finished extracting.\n",
            "Extracting image sets ['data/extracted/omniglot-master/python/images_background.zip', 'data/extracted/omniglot-master/python/images_evaluation.zip']\n",
            "Done extracting image sets.\n",
            "Converting folder images_background to numpy array...\n",
            "Done.\n",
            "Converting folder images_evaluation to numpy array...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "taken and modified from: https://github.com/pranv/ARC/blob/master/image_augmenter.py which was in turn\n",
        "taken and modified from: https://github.com/aleju/ImageAugmenter\n",
        "\"\"\"\n",
        "\n",
        "# The MIT License (MIT)\n",
        "#\n",
        "# Copyright (c) 2015 aleju\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all\n",
        "# copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Wrapper functions and classes around scikit-images AffineTransformation.\n",
        "Simplifies augmentation of images in machine learning.\n",
        "Example usage:\n",
        "        img_width = 32 # width of the images\n",
        "        img_height = 32 # height of the images\n",
        "        images = ... # e.g. load via scipy.misc.imload(filename)\n",
        "        # For each image: randomly flip it horizontally (50% chance),\n",
        "        # randomly rotate it between -20 and +20 degrees, randomly translate\n",
        "        # it on the x-axis between -5 and +5 pixel.\n",
        "        ia = ImageAugmenter(img_width, img_height, hlip=True, rotation_deg=20,\n",
        "                            translation_x_px=5)\n",
        "        augmented_images = ia.augment_batch(images)\n",
        "\"\"\"\n",
        "\n",
        "def is_minmax_tuple(param):\n",
        "    \"\"\"Returns whether the parameter is a tuple containing two values.\n",
        "    Used in create_aug_matrices() and probably useless everywhere else.\n",
        "    Args:\n",
        "        param: The parameter to check (whether it is a tuple of length 2).\n",
        "    Returns:\n",
        "        Boolean\n",
        "    \"\"\"\n",
        "    return type(param) is tuple and len(param) == 2\n",
        "\n",
        "def create_aug_matrices(nb_matrices, img_width_px, img_height_px,\n",
        "                        scale_to_percent=1.0, scale_axis_equally=False,\n",
        "                        rotation_deg=0, shear_deg=0,\n",
        "                        translation_x_px=0, translation_y_px=0,\n",
        "                        seed=None):\n",
        "    \"\"\"Creates the augmentation matrices that may later be used to transform\n",
        "    images.\n",
        "    This is a wrapper around scikit-image's transform.AffineTransform class.\n",
        "    You can apply those matrices to images using the apply_aug_matrices()\n",
        "    function.\n",
        "    Args:\n",
        "        nb_matrices: How many matrices to return, e.g. 100 returns 100 different\n",
        "            random-generated matrices (= 100 different transformations).\n",
        "        img_width_px: Width of the images that will be transformed later\n",
        "            on (same as the width of each of the matrices).\n",
        "        img_height_px: Height of the images that will be transformed later\n",
        "            on (same as the height of each of the matrices).\n",
        "        scale_to_percent: Same as in ImageAugmenter.__init__().\n",
        "            Up to which percentage the images may be\n",
        "            scaled/zoomed. The negative scaling is automatically derived\n",
        "            from this value. A value of 1.1 allows scaling by any value\n",
        "            between -10% and +10%. You may set min and max values yourself\n",
        "            by using a tuple instead, like (1.1, 1.2) to scale between\n",
        "            +10% and +20%. Default is 1.0 (no scaling).\n",
        "        scale_axis_equally: Same as in ImageAugmenter.__init__().\n",
        "            Whether to always scale both axis (x and y)\n",
        "            in the same way. If set to False, then e.g. the Augmenter\n",
        "            might scale the x-axis by 20% and the y-axis by -5%.\n",
        "            Default is False.\n",
        "        rotation_deg: Same as in ImageAugmenter.__init__().\n",
        "            By how much the image may be rotated around its\n",
        "            center (in degrees). The negative rotation will automatically\n",
        "            be derived from this value. E.g. a value of 20 allows any\n",
        "            rotation between -20 degrees and +20 degrees. You may set min\n",
        "            and max values yourself by using a tuple instead, e.g. (5, 20)\n",
        "            to rotate between +5 und +20 degrees. Default is 0 (no\n",
        "            rotation).\n",
        "        shear_deg: Same as in ImageAugmenter.__init__().\n",
        "            By how much the image may be sheared (in degrees). The\n",
        "            negative value will automatically be derived from this value.\n",
        "            E.g. a value of 20 allows any shear between -20 degrees and\n",
        "            +20 degrees. You may set min and max values yourself by using a\n",
        "            tuple instead, e.g. (5, 20) to shear between +5 und +20\n",
        "            degrees. Default is 0 (no shear).\n",
        "        translation_x_px: Same as in ImageAugmenter.__init__().\n",
        "            By up to how many pixels the image may be\n",
        "            translated (moved) on the x-axis. The negative value will\n",
        "            automatically be derived from this value. E.g. a value of +7\n",
        "            allows any translation between -7 and +7 pixels on the x-axis.\n",
        "            You may set min and max values yourself by using a tuple\n",
        "            instead, e.g. (5, 20) to translate between +5 und +20 pixels.\n",
        "            Default is 0 (no translation on the x-axis).\n",
        "        translation_y_px: Same as in ImageAugmenter.__init__().\n",
        "            See translation_x_px, just for the y-axis.\n",
        "        seed: Seed to use for python's and numpy's random functions.\n",
        "    Returns:\n",
        "        List of augmentation matrices.\n",
        "    \"\"\"\n",
        "    assert nb_matrices > 0\n",
        "    assert img_width_px > 0\n",
        "    assert img_height_px > 0\n",
        "    assert is_minmax_tuple(scale_to_percent) or scale_to_percent >= 1.0\n",
        "    assert is_minmax_tuple(rotation_deg) or rotation_deg >= 0\n",
        "    assert is_minmax_tuple(shear_deg) or shear_deg >= 0\n",
        "    assert is_minmax_tuple(translation_x_px) or translation_x_px >= 0\n",
        "    assert is_minmax_tuple(translation_y_px) or translation_y_px >= 0\n",
        "\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    result = []\n",
        "\n",
        "    shift_x = int(img_width_px / 2.0)\n",
        "    shift_y = int(img_height_px / 2.0)\n",
        "\n",
        "    # prepare min and max values for\n",
        "    # scaling/zooming (min/max values)\n",
        "    if is_minmax_tuple(scale_to_percent):\n",
        "        scale_x_min = scale_to_percent[0]\n",
        "        scale_x_max = scale_to_percent[1]\n",
        "    else:\n",
        "        scale_x_min = scale_to_percent\n",
        "        scale_x_max = 1.0 - (scale_to_percent - 1.0)\n",
        "    assert scale_x_min > 0.0\n",
        "    #if scale_x_max >= 2.0:\n",
        "    #     warnings.warn(\"Scaling by more than 100 percent (%.2f).\" % (scale_x_max,))\n",
        "    scale_y_min = scale_x_min # scale_axis_equally affects the random value generation\n",
        "    scale_y_max = scale_x_max\n",
        "\n",
        "    # rotation (min/max values)\n",
        "    if is_minmax_tuple(rotation_deg):\n",
        "        rotation_deg_min = rotation_deg[0]\n",
        "        rotation_deg_max = rotation_deg[1]\n",
        "    else:\n",
        "        rotation_deg_min = (-1) * int(rotation_deg)\n",
        "        rotation_deg_max = int(rotation_deg)\n",
        "\n",
        "    # shear (min/max values)\n",
        "    if is_minmax_tuple(shear_deg):\n",
        "        shear_deg_min = shear_deg[0]\n",
        "        shear_deg_max = shear_deg[1]\n",
        "    else:\n",
        "        shear_deg_min = (-1) * int(shear_deg)\n",
        "        shear_deg_max = int(shear_deg)\n",
        "\n",
        "    # translation x-axis (min/max values)\n",
        "    if is_minmax_tuple(translation_x_px):\n",
        "        translation_x_px_min = translation_x_px[0]\n",
        "        translation_x_px_max = translation_x_px[1]\n",
        "    else:\n",
        "        translation_x_px_min = (-1) * translation_x_px\n",
        "        translation_x_px_max = translation_x_px\n",
        "\n",
        "    # translation y-axis (min/max values)\n",
        "    if is_minmax_tuple(translation_y_px):\n",
        "        translation_y_px_min = translation_y_px[0]\n",
        "        translation_y_px_max = translation_y_px[1]\n",
        "    else:\n",
        "        translation_y_px_min = (-1) * translation_y_px\n",
        "        translation_y_px_max = translation_y_px\n",
        "\n",
        "    # create nb_matrices randomized affine transformation matrices\n",
        "    for _ in range(nb_matrices):\n",
        "        # generate random values for scaling, rotation, shear, translation\n",
        "        scale_x = random.uniform(scale_x_min, scale_x_max)\n",
        "        scale_y = random.uniform(scale_y_min, scale_y_max)\n",
        "        if not scale_axis_equally:\n",
        "            scale_y = random.uniform(scale_y_min, scale_y_max)\n",
        "        else:\n",
        "            scale_y = scale_x\n",
        "        rotation = np.deg2rad(random.randint(rotation_deg_min, rotation_deg_max))\n",
        "        shear = np.deg2rad(random.randint(shear_deg_min, shear_deg_max))\n",
        "        translation_x = random.randint(translation_x_px_min, translation_x_px_max)\n",
        "        translation_y = random.randint(translation_y_px_min, translation_y_px_max)\n",
        "\n",
        "        # create three affine transformation matrices\n",
        "        # 1st one moves the image to the top left, 2nd one transforms it, 3rd one\n",
        "        # moves it back to the center.\n",
        "        # The movement is neccessary, because rotation is applied to the top left\n",
        "        # and not to the image's center (same for scaling and shear).\n",
        "        matrix_to_topleft = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\n",
        "        matrix_transforms = tf.AffineTransform(scale=(scale_x, scale_y),\n",
        "                                               rotation=rotation, shear=shear,\n",
        "                                               translation=(translation_x,\n",
        "                                                            translation_y))\n",
        "        matrix_to_center = tf.SimilarityTransform(translation=[shift_x, shift_y])\n",
        "\n",
        "        # Combine the three matrices to one affine transformation (one matrix)\n",
        "        matrix = matrix_to_topleft + matrix_transforms + matrix_to_center\n",
        "\n",
        "        # one matrix is ready, add it to the result\n",
        "        result.append(matrix.inverse)\n",
        "\n",
        "    return result\n",
        "\n",
        "def apply_aug_matrices(images, matrices, transform_channels_equally=True,\n",
        "                       channel_is_first_axis=False, random_order=True,\n",
        "                       mode=\"constant\", cval=0.0, interpolation_order=1,\n",
        "                       seed=None):\n",
        "    \"\"\"Augment the given images using the given augmentation matrices.\n",
        "    This function is a wrapper around scikit-image's transform.warp().\n",
        "    It is expected to be called by ImageAugmenter.augment_batch().\n",
        "    The matrices may be generated by create_aug_matrices().\n",
        "    Args:\n",
        "        images: Same as in ImageAugmenter.augment_batch().\n",
        "            Numpy array (dtype: uint8, i.e. values 0-255) with the images.\n",
        "            Expected shape is either (image-index, height, width) for\n",
        "            grayscale images or (image-index, channel, height, width) for\n",
        "            images with channels (e.g. RGB) where the channel has the first\n",
        "            index or (image-index, height, width, channel) for images with\n",
        "            channels, where the channel is the last index.\n",
        "            If your shape is (image-index, channel, width, height) then\n",
        "            you must also set channel_is_first_axis=True in the constructor.\n",
        "        matrices: A list of augmentation matrices as produced by\n",
        "            create_aug_matrices().\n",
        "        transform_channels_equally: Same as in ImageAugmenter.__init__().\n",
        "            Whether to apply the exactly same\n",
        "            transformations to each channel of an image (True). Setting\n",
        "            it to False allows different transformations per channel,\n",
        "            e.g. the red-channel might be rotated by +20 degrees, while\n",
        "            the blue channel (of the same image) might be rotated\n",
        "            by -5 degrees. If you don't have any channels (2D grayscale),\n",
        "            you can simply ignore this setting.\n",
        "            Default is True (transform all equally).\n",
        "        channel_is_first_axis: Same as in ImageAugmenter.__init__().\n",
        "            Whether the channel (e.g. RGB) is the first\n",
        "            axis of each image (True) or the last axis (False).\n",
        "            False matches the scipy and PIL implementation and is the\n",
        "            default. If your images are 2D-grayscale then you can ignore\n",
        "            this setting (as the augmenter will ignore it too).\n",
        "        random_order: Whether to apply the augmentation matrices in a random\n",
        "            order (True, e.g. the 2nd matrix might be applied to the\n",
        "            5th image) or in the given order (False, e.g. the 2nd matrix might\n",
        "            be applied to the 2nd image).\n",
        "            Notice that for multi-channel images (e.g. RGB) this function\n",
        "            will use a different matrix for each channel, unless\n",
        "            transform_channels_equally is set to True.\n",
        "        mode: Parameter used for the transform.warp-function of scikit-image.\n",
        "            Can usually be ignored.\n",
        "        cval: Parameter used for the transform.warp-function of scikit-image.\n",
        "            Defines the fill color for \"new\" pixels, e.g. for empty areas\n",
        "            after rotations. (0.0 is black, 1.0 is white.)\n",
        "        interpolation_order: Parameter used for the transform.warp-function of\n",
        "            scikit-image. Defines the order of all interpolations used to\n",
        "            generate the new/augmented image. See their documentation for\n",
        "            further details.\n",
        "        seed: Seed to use for python's and numpy's random functions.\n",
        "    \"\"\"\n",
        "    # images must be numpy array\n",
        "    assert type(images).__module__ == np.__name__, \"Expected numpy array for \" \\\n",
        "                                                   \"parameter 'images'.\"\n",
        "\n",
        "    # images must have uint8 as dtype (0-255)\n",
        "    assert images.dtype.name == \"uint8\", \"Expected numpy.uint8 as image dtype.\"\n",
        "\n",
        "    # 3 axis total (2 per image) for grayscale,\n",
        "    # 4 axis total (3 per image) for RGB (usually)\n",
        "    assert len(images.shape) in [3, 4], \"\"\"Expected 'images' parameter to have\n",
        "        either shape (image index, y, x) for greyscale\n",
        "        or (image index, channel, y, x) / (image index, y, x, channel)\n",
        "        for multi-channel (usually color) images.\"\"\"\n",
        "\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    nb_images = images.shape[0]\n",
        "\n",
        "    # estimate number of channels, set to 1 if there is no axis channel,\n",
        "    # otherwise it will usually be 3\n",
        "    has_channels = False\n",
        "    nb_channels = 1\n",
        "    if len(images.shape) == 4:\n",
        "        has_channels = True\n",
        "        if channel_is_first_axis:\n",
        "            nb_channels = images.shape[1] # first axis within each image\n",
        "        else:\n",
        "            nb_channels = images.shape[3] # last axis within each image\n",
        "\n",
        "    # whether to apply the transformations directly to the whole image\n",
        "    # array (True) or for each channel individually (False)\n",
        "    apply_directly = not has_channels or (transform_channels_equally\n",
        "                                          and not channel_is_first_axis)\n",
        "\n",
        "    # We generate here the order in which the matrices may be applied.\n",
        "    # At the end, order_indices will contain the index of the matrix to use\n",
        "    # for each image, e.g. [15, 2] would mean, that the 15th matrix will be\n",
        "    # applied to the 0th image, the 2nd matrix to the 1st image.\n",
        "    # If the images gave multiple channels (e.g. RGB) and\n",
        "    # transform_channels_equally has been set to False, we will need one\n",
        "    # matrix per channel instead of per image.\n",
        "\n",
        "    # 0 to nb_images, but restart at 0 if index is beyond number of matrices\n",
        "    len_indices = nb_images if apply_directly else nb_images * nb_channels\n",
        "    if random_order:\n",
        "        # Notice: This way to choose random matrices is concise, but can create\n",
        "        # problems if there is a low amount of images and matrices.\n",
        "        # E.g. suppose that 2 images are ought to be transformed by either\n",
        "        # 0px translation on the x-axis or 1px translation. So 50% of all\n",
        "        # matrices translate by 0px and 50% by 1px. The following method\n",
        "        # will randomly choose a combination of the two matrices for the\n",
        "        # two images (matrix 0 for image 0 and matrix 0 for image 1,\n",
        "        # matrix 0 for image 0 and matrix 1 for image 1, ...).\n",
        "        # In 50% of these cases, a different matrix will be chosen for image 0\n",
        "        # and image 1 (matrices 0, 1 or matrices 1, 0). But 50% of these\n",
        "        # \"different\" matrices (different index) will be the same, as 50%\n",
        "        # translate by 1px and 50% by 0px. As a result, 75% of all augmentations\n",
        "        # will transform both images in the same way.\n",
        "        # The effect decreases if more matrices or images are chosen.\n",
        "        order_indices = np.random.random_integers(0, len(matrices) - 1, len_indices)\n",
        "    else:\n",
        "        # monotonously growing indexes (each by +1), but none of them may be\n",
        "        # higher than or equal to the number of matrices\n",
        "        order_indices = np.arange(0, len_indices) % len(matrices)\n",
        "\n",
        "    result = np.zeros(images.shape, dtype=np.float32)\n",
        "    matrix_number = 0\n",
        "\n",
        "    # iterate over every image, find out which matrix to apply and then use\n",
        "    # that matrix to augment the image\n",
        "    for img_idx, image in enumerate(images):\n",
        "        if apply_directly:\n",
        "            # we can apply the matrix to the whole numpy array of the image\n",
        "            # at the same time, so we do that to save time (instead of eg. three\n",
        "            # steps for three channels as in the else-part)\n",
        "            matrix = matrices[order_indices[matrix_number]]\n",
        "            result[img_idx, ...] = tf.warp(image, matrix, mode=mode, cval=cval,\n",
        "                                           order=interpolation_order)\n",
        "            matrix_number += 1\n",
        "        else:\n",
        "            # we cant apply the matrix to the whole image in one step, instead\n",
        "            # we have to apply it to each channel individually. that happens\n",
        "            # if the channel is the first axis of each image (incompatible with\n",
        "            # tf.warp()) or if it was explicitly requested via\n",
        "            # transform_channels_equally=False.\n",
        "            for channel_idx in range(nb_channels):\n",
        "                matrix = matrices[order_indices[matrix_number]]\n",
        "                if channel_is_first_axis:\n",
        "                    warped = tf.warp(image[channel_idx], matrix, mode=mode,\n",
        "                                     cval=cval, order=interpolation_order)\n",
        "                    result[img_idx, channel_idx, ...] = warped\n",
        "                else:\n",
        "                    warped = tf.warp(image[..., channel_idx], matrix, mode=mode,\n",
        "                                     cval=cval, order=interpolation_order)\n",
        "                    result[img_idx, ..., channel_idx] = warped\n",
        "\n",
        "                if not transform_channels_equally:\n",
        "                    matrix_number += 1\n",
        "            if transform_channels_equally:\n",
        "                matrix_number += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "class ImageAugmenter(object):\n",
        "    \"\"\"Helper class to randomly augment images, usually for neural networks.\n",
        "    Example usage:\n",
        "        img_width = 32 # width of the images\n",
        "        img_height = 32 # height of the images\n",
        "        images = ... # e.g. load via scipy.misc.imload(filename)\n",
        "        # For each image: randomly flip it horizontally (50% chance),\n",
        "        # randomly rotate it between -20 and +20 degrees, randomly translate\n",
        "        # it on the x-axis between -5 and +5 pixel.\n",
        "        ia = ImageAugmenter(img_width, img_height, hlip=True, rotation_deg=20,\n",
        "                            translation_x_px=5)\n",
        "        augmented_images = ia.augment_batch(images)\n",
        "    \"\"\"\n",
        "    def __init__(self, img_width_px, img_height_px, channel_is_first_axis=False,\n",
        "                 hflip=False, vflip=False,\n",
        "                 scale_to_percent=1.0, scale_axis_equally=False,\n",
        "                 rotation_deg=0, shear_deg=0,\n",
        "                 translation_x_px=0, translation_y_px=0,\n",
        "                 transform_channels_equally=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_width_px: The intended width of each image in pixels.\n",
        "            img_height_px: The intended height of each image in pixels.\n",
        "            channel_is_first_axis: Whether the channel (e.g. RGB) is the first\n",
        "                axis of each image (True) or the last axis (False).\n",
        "                False matches the scipy and PIL implementation and is the\n",
        "                default. If your images are 2D-grayscale then you can ignore\n",
        "                this setting (as the augmenter will ignore it too).\n",
        "            hflip: Whether to randomly flip images horizontally (on the y-axis).\n",
        "                You may choose either False (no horizontal flipping),\n",
        "                True (flip with probability 0.5) or use a float\n",
        "                value (probability) between 0.0 and 1.0. Default is False.\n",
        "            vflip: Whether to randomly flip images vertically (on the x-axis).\n",
        "                You may choose either False (no vertical flipping),\n",
        "                True (flip with probability 0.5) or use a float\n",
        "                value (probability) between 0.0 and 1.0. Default is False.\n",
        "            scale_to_percent: Up to which percentage the images may be\n",
        "                scaled/zoomed. The negative scaling is automatically derived\n",
        "                from this value. A value of 1.1 allows scaling by any value\n",
        "                between -10% and +10%. You may set min and max values yourself\n",
        "                by using a tuple instead, like (1.1, 1.2) to scale between\n",
        "                +10% and +20%. Default is 1.0 (no scaling).\n",
        "            scale_axis_equally: Whether to always scale both axis (x and y)\n",
        "                in the same way. If set to False, then e.g. the Augmenter\n",
        "                might scale the x-axis by 20% and the y-axis by -5%.\n",
        "                Default is False.\n",
        "            rotation_deg: By how much the image may be rotated around its\n",
        "                center (in degrees). The negative rotation will automatically\n",
        "                be derived from this value. E.g. a value of 20 allows any\n",
        "                rotation between -20 degrees and +20 degrees. You may set min\n",
        "                and max values yourself by using a tuple instead, e.g. (5, 20)\n",
        "                to rotate between +5 und +20 degrees. Default is 0 (no\n",
        "                rotation).\n",
        "            shear_deg: By how much the image may be sheared (in degrees). The\n",
        "                negative value will automatically be derived from this value.\n",
        "                E.g. a value of 20 allows any shear between -20 degrees and\n",
        "                +20 degrees. You may set min and max values yourself by using a\n",
        "                tuple instead, e.g. (5, 20) to shear between +5 und +20\n",
        "                degrees. Default is 0 (no shear).\n",
        "            translation_x_px: By up to how many pixels the image may be\n",
        "                translated (moved) on the x-axis. The negative value will\n",
        "                automatically be derived from this value. E.g. a value of +7\n",
        "                allows any translation between -7 and +7 pixels on the x-axis.\n",
        "                You may set min and max values yourself by using a tuple\n",
        "                instead, e.g. (5, 20) to translate between +5 und +20 pixels.\n",
        "                Default is 0 (no translation on the x-axis).\n",
        "            translation_y_px: See translation_x_px, just for the y-axis.\n",
        "            transform_channels_equally: Whether to apply the exactly same\n",
        "                transformations to each channel of an image (True). Setting\n",
        "                it to False allows different transformations per channel,\n",
        "                e.g. the red-channel might be rotated by +20 degrees, while\n",
        "                the blue channel (of the same image) might be rotated\n",
        "                by -5 degrees. If you don't have any channels (2D grayscale),\n",
        "                you can simply ignore this setting.\n",
        "                Default is True (transform all equally).\n",
        "        \"\"\"\n",
        "        self.img_width_px = img_width_px\n",
        "        self.img_height_px = img_height_px\n",
        "        self.channel_is_first_axis = channel_is_first_axis\n",
        "\n",
        "        self.hflip_prob = 0.0\n",
        "        # note: we have to check first for floats, otherwise \"hflip == True\"\n",
        "        # will evaluate to true if hflip is 1.0. So chosing 1.0 (100%) would\n",
        "        # result in hflip_prob to be set to 0.5 (50%).\n",
        "        if isinstance(hflip, float):\n",
        "            assert hflip >= 0.0 and hflip <= 1.0\n",
        "            self.hflip_prob = hflip\n",
        "        elif hflip == True:\n",
        "            self.hflip_prob = 0.5\n",
        "        elif hflip == False:\n",
        "            self.hflip_prob = 0.0\n",
        "        else:\n",
        "            raise Exception(\"Unexpected value for parameter 'hflip'.\")\n",
        "\n",
        "        self.vflip_prob = 0.0\n",
        "        if isinstance(vflip, float):\n",
        "            assert vflip >= 0.0 and vflip <= 1.0\n",
        "            self.vflip_prob = vflip\n",
        "        elif vflip == True:\n",
        "            self.vflip_prob = 0.5\n",
        "        elif vflip == False:\n",
        "            self.vflip_prob = 0.0\n",
        "        else:\n",
        "            raise Exception(\"Unexpected value for parameter 'vflip'.\")\n",
        "\n",
        "        self.scale_to_percent = scale_to_percent\n",
        "        self.scale_axis_equally = scale_axis_equally\n",
        "        self.rotation_deg = rotation_deg\n",
        "        self.shear_deg = shear_deg\n",
        "        self.translation_x_px = translation_x_px\n",
        "        self.translation_y_px = translation_y_px\n",
        "        self.transform_channels_equally = transform_channels_equally\n",
        "        self.cval = 0.0\n",
        "        self.interpolation_order = 1\n",
        "        self.pregenerated_matrices = None\n",
        "\n",
        "    def pregenerate_matrices(self, nb_matrices, seed=None):\n",
        "        \"\"\"Pregenerate/cache augmentation matrices.\n",
        "        If matrices are pregenerated, augment_batch() will reuse them on\n",
        "        each call. The augmentations will not always be the same,\n",
        "        as the order of the matrices will be randomized (when\n",
        "        they are applied to the images). The requirement for that is though\n",
        "        that you pregenerate enough of them (e.g. a couple thousand).\n",
        "        Note that generating the augmentation matrices is usually fast\n",
        "        and only starts to make sense if you process millions of small images\n",
        "        or many tens of thousands of big images.\n",
        "        Each call to this method results in pregenerating a new set of matrices,\n",
        "        e.g. to replace a list of matrices that has been used often enough.\n",
        "        Calling this method with nb_matrices set to 0 will remove the\n",
        "        pregenerated matrices and augment_batch() returns to its default\n",
        "        behaviour of generating new matrices on each call.\n",
        "        Args:\n",
        "            nb_matrices: The number of matrices to pregenerate. E.g. a few\n",
        "                thousand. If set to 0, the matrices will be generated again on\n",
        "                each call of augment_batch().\n",
        "            seed: A random seed to use.\n",
        "        \"\"\"\n",
        "        assert nb_matrices >= 0\n",
        "        if nb_matrices == 0:\n",
        "            self.pregenerated_matrices = None\n",
        "        else:\n",
        "            matrices = create_aug_matrices(nb_matrices,\n",
        "                                           self.img_width_px,\n",
        "                                           self.img_height_px,\n",
        "                                           scale_to_percent=self.scale_to_percent,\n",
        "                                           scale_axis_equally=self.scale_axis_equally,\n",
        "                                           rotation_deg=self.rotation_deg,\n",
        "                                           shear_deg=self.shear_deg,\n",
        "                                           translation_x_px=self.translation_x_px,\n",
        "                                           translation_y_px=self.translation_y_px,\n",
        "                                           seed=seed)\n",
        "            self.pregenerated_matrices = matrices\n",
        "\n",
        "    def augment_batch(self, images, seed=None):\n",
        "        \"\"\"Augments a batch of images.\n",
        "        Applies all settings (rotation, shear, translation, ...) that\n",
        "        have been chosen in the constructor.\n",
        "        Args:\n",
        "            images: Numpy array (dtype: uint8, i.e. values 0-255) with the images.\n",
        "                Expected shape is either (image-index, height, width) for\n",
        "                grayscale images or (image-index, channel, height, width) for\n",
        "                images with channels (e.g. RGB) where the channel has the first\n",
        "                index or (image-index, height, width, channel) for images with\n",
        "                channels, where the channel is the last index.\n",
        "                If your shape is (image-index, channel, width, height) then\n",
        "                you must also set channel_is_first_axis=True in the constructor.\n",
        "            seed: Seed to use for python's and numpy's random functions.\n",
        "                Default is None (dont use a seed).\n",
        "        Returns:\n",
        "            Augmented images as numpy array of dtype float32 (i.e. values\n",
        "            are between 0.0 and 1.0).\n",
        "        \"\"\"\n",
        "        shape = images.shape\n",
        "        nb_channels = 0\n",
        "        if len(shape) == 3:\n",
        "            # shape like (image_index, y-axis, x-axis)\n",
        "            assert shape[1] == self.img_height_px\n",
        "            assert shape[2] == self.img_width_px\n",
        "            nb_channels = 1\n",
        "        elif len(shape) == 4:\n",
        "            if not self.channel_is_first_axis:\n",
        "                # shape like (image-index, y-axis, x-axis, channel-index)\n",
        "                assert shape[1] == self.img_height_px\n",
        "                assert shape[2] == self.img_width_px\n",
        "                nb_channels = shape[3]\n",
        "            else:\n",
        "                # shape like (image-index, channel-index, y-axis, x-axis)\n",
        "                assert shape[2] == self.img_height_px\n",
        "                assert shape[3] == self.img_width_px\n",
        "                nb_channels = shape[1]\n",
        "        else:\n",
        "            msg = \"Mismatch between images shape %s and \" \\\n",
        "                  \"predefined image width/height (%d/%d).\"\n",
        "            raise Exception(msg % (str(shape), self.img_width_px, self.img_height_px))\n",
        "\n",
        "        if seed:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        # --------------------------------\n",
        "        # horizontal and vertical flipping/mirroring\n",
        "        # --------------------------------\n",
        "        # This should be done before applying the affine matrices, as otherwise\n",
        "        # contents of image might already be rotated/translated out of the image.\n",
        "        # It is done with numpy instead of the affine matrices, because\n",
        "        # scikit-image doesn't offer a nice interface to add mirroring/flipping\n",
        "        # to affine transformations. The numpy operations are O(1), so they\n",
        "        # shouldn't have a noticeable effect on runtimes. They also won't suffer\n",
        "        # from interpolation problems.\n",
        "        if self.hflip_prob > 0 or self.vflip_prob > 0:\n",
        "            # TODO this currently ignores the setting in\n",
        "            # transform_channels_equally and will instead always flip all\n",
        "            # channels equally\n",
        "\n",
        "            # if this is simply a view, then the input array gets flipped too\n",
        "            # for some reason\n",
        "            images_flipped = np.copy(images)\n",
        "            #images_flipped = images.view()\n",
        "\n",
        "            if len(shape) == 4 and self.channel_is_first_axis:\n",
        "                # roll channel to the last axis\n",
        "                # swapaxes doesnt work here, because\n",
        "                #  (image index, channel, y, x)\n",
        "                # would be turned into\n",
        "                #  (image index, x, y, channel)\n",
        "                # and y needs to come before x\n",
        "                images_flipped = np.rollaxis(images_flipped, 1, 4)\n",
        "\n",
        "            y_p = self.hflip_prob\n",
        "            x_p = self.vflip_prob\n",
        "            batch_size = images.shape[0] // 2\n",
        "            for i in range(batch_size):\n",
        "                if y_p > 0 and random.random() < y_p:\n",
        "                    images_flipped[i] = np.fliplr(images_flipped[i])\n",
        "                    images_flipped[i+batch_size] = np.fliplr(images_flipped[i+batch_size])\n",
        "                if x_p > 0 and random.random() < x_p:\n",
        "                    images_flipped[i] = np.flipud(images_flipped[i])\n",
        "                    images_flipped[i+batch_size] = np.flipud(images_flipped[i+batch_size])\n",
        "\n",
        "            if len(shape) == 4 and self.channel_is_first_axis:\n",
        "                # roll channel back to the second axis (index 1)\n",
        "                images_flipped = np.rollaxis(images_flipped, 3, 1)\n",
        "            images = images_flipped\n",
        "\n",
        "        # --------------------------------\n",
        "        # if no augmentation has been chosen, stop early\n",
        "        # for improved performance (evade applying matrices)\n",
        "        # --------------------------------\n",
        "        if self.pregenerated_matrices is None \\\n",
        "           and self.scale_to_percent == 1.0 and self.rotation_deg == 0 \\\n",
        "           and self.shear_deg == 0 \\\n",
        "           and self.translation_x_px == 0 and self.translation_y_px == 0:\n",
        "            return np.array(images, dtype=np.float32) / 255\n",
        "\n",
        "        # --------------------------------\n",
        "        # generate transformation matrices\n",
        "        # --------------------------------\n",
        "        if self.pregenerated_matrices is not None:\n",
        "            matrices = self.pregenerated_matrices\n",
        "        else:\n",
        "            # estimate the number of matrices required\n",
        "            if self.transform_channels_equally:\n",
        "                nb_matrices = shape[0]\n",
        "            else:\n",
        "                nb_matrices = shape[0] * nb_channels\n",
        "\n",
        "            # generate matrices\n",
        "            matrices = create_aug_matrices(nb_matrices,\n",
        "                                           self.img_width_px,\n",
        "                                           self.img_height_px,\n",
        "                                           scale_to_percent=self.scale_to_percent,\n",
        "                                           scale_axis_equally=self.scale_axis_equally,\n",
        "                                           rotation_deg=self.rotation_deg,\n",
        "                                           shear_deg=self.shear_deg,\n",
        "                                           translation_x_px=self.translation_x_px,\n",
        "                                           translation_y_px=self.translation_y_px,\n",
        "                                           seed=seed)\n",
        "\n",
        "        # --------------------------------\n",
        "        # apply transformation matrices (i.e. augment images)\n",
        "        # --------------------------------\n",
        "        return apply_aug_matrices(images, matrices,\n",
        "                                  transform_channels_equally=self.transform_channels_equally,\n",
        "                                  channel_is_first_axis=self.channel_is_first_axis,\n",
        "                                  cval=self.cval, interpolation_order=self.interpolation_order,\n",
        "                                  seed=seed)\n",
        "\n",
        "    def plot_image(self, image, nb_repeat=40, show_plot=True):\n",
        "        \"\"\"Plot augmented variations of an image.\n",
        "        This method takes an image and plots it by default in 40 differently\n",
        "        augmented versions.\n",
        "        This method is intended to visualize the strength of your chosen\n",
        "        augmentations (so for debugging).\n",
        "        Args:\n",
        "            image: The image to plot.\n",
        "            nb_repeat: How often to plot the image. Each time it is plotted,\n",
        "                the chosen augmentation will be different. (Default: 40).\n",
        "            show_plot: Whether to show the plot. False makes sense if you\n",
        "                don't have a graphical user interface on the machine.\n",
        "                (Default: True)\n",
        "        Returns:\n",
        "            The figure of the plot.\n",
        "            Use figure.savefig() to save the image.\n",
        "        \"\"\"\n",
        "        if len(image.shape) == 2:\n",
        "            images = np.resize(image, (nb_repeat, image.shape[0], image.shape[1]))\n",
        "        else:\n",
        "            images = np.resize(image, (nb_repeat, image.shape[0], image.shape[1],\n",
        "                               image.shape[2]))\n",
        "        return self.plot_images(images, True, show_plot=show_plot)\n",
        "\n",
        "    def plot_images(self, images, augment, show_plot=True, figure=None):\n",
        "        \"\"\"Plot augmented variations of images.\n",
        "        The images will all be shown in the same window.\n",
        "        It is recommended to not plot too many of them (i.e. stay below 100).\n",
        "        This method is intended to visualize the strength of your chosen\n",
        "        augmentations (so for debugging).\n",
        "        Args:\n",
        "            images: A numpy array of images. See augment_batch().\n",
        "            augment: Whether to augment the images (True) or just display\n",
        "                them in the way they are (False).\n",
        "            show_plot: Whether to show the plot. False makes sense if you\n",
        "                don't have a graphical user interface on the machine.\n",
        "                (Default: True)\n",
        "            figure: The figure of the plot in which to draw the images.\n",
        "                Provide the return value of this function (from a prior call)\n",
        "                to draw in the same plot window again. Chosing 'None' will\n",
        "                create a new figure. (Default is None.)\n",
        "        Returns:\n",
        "            The figure of the plot.\n",
        "            Use figure.savefig() to save the image.\n",
        "        \"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import matplotlib.cm as cm\n",
        "\n",
        "        if augment:\n",
        "            images = self.augment_batch(images)\n",
        "\n",
        "        # (Lists of) Grayscale images have the shape (image index, y, x)\n",
        "        # Multi-Channel images therefore must have 4 or more axes here\n",
        "        if len(images.shape) >= 4:\n",
        "            # The color-channel is expected to be the last axis by matplotlib\n",
        "            # therefore exchange the axes, if its the first one here\n",
        "            if self.channel_is_first_axis:\n",
        "                images = np.rollaxis(images, 1, 4)\n",
        "\n",
        "        nb_cols = 10\n",
        "        nb_rows = 1 + int(images.shape[0] / nb_cols)\n",
        "        if figure is not None:\n",
        "            fig = figure\n",
        "            plt.figure(fig.number)\n",
        "            fig.clear()\n",
        "        else:\n",
        "            fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            image = images[i]\n",
        "\n",
        "            plot_number = i + 1\n",
        "            ax = fig.add_subplot(nb_rows, nb_cols, plot_number, xticklabels=[],\n",
        "                                 yticklabels=[])\n",
        "            ax.set_axis_off()\n",
        "            # \"cmap\" should restrict the color map to grayscale, but strangely\n",
        "            # also works well with color images\n",
        "            imgplot = plt.imshow(image, cmap=cm.Greys_r, aspect=\"equal\")\n",
        "\n",
        "        # not showing the plot might be useful e.g. on clusters\n",
        "        if show_plot:\n",
        "            plt.show()\n",
        "\n",
        "        return "
      ],
      "metadata": {
        "id": "QM_SYMl3zxk1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = False\n",
        "\n",
        "\n",
        "class GlimpseWindow:\n",
        "    \"\"\"\n",
        "    Generates glimpses from images using Cauchy kernels.\n",
        "    Args:\n",
        "        glimpse_h (int): The height of the glimpses to be generated.\n",
        "        glimpse_w (int): The width of the glimpses to be generated.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, glimpse_h: int, glimpse_w: int):\n",
        "        self.glimpse_h = glimpse_h\n",
        "        self.glimpse_w = glimpse_w\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_filterbanks(delta_caps: Variable, center_caps: Variable, image_size: int, glimpse_size: int) -> Variable:\n",
        "        \"\"\"\n",
        "        Generates Cauchy Filter Banks along a dimension.\n",
        "        Args:\n",
        "            delta_caps (B,):  A batch of deltas [-1, 1]\n",
        "            center_caps (B,): A batch of [-1, 1] reals that dictate the location of center of cauchy kernel glimpse.\n",
        "            image_size (int): size of images along that dimension\n",
        "            glimpse_size (int): size of glimpses to be generated along that dimension\n",
        "        Returns:\n",
        "            (B, image_size, glimpse_size): A batch of filter banks\n",
        "        \"\"\"\n",
        "\n",
        "        # convert dimension sizes to float. lots of math ahead.\n",
        "        image_size = float(image_size)\n",
        "        glimpse_size = float(glimpse_size)\n",
        "\n",
        "        # scale the centers and the deltas to map to the actual size of given image.\n",
        "        centers = (image_size - 1) * (center_caps + 1) / 2.0  # (B)\n",
        "        deltas = (float(image_size) / glimpse_size) * (1.0 - torch.abs(delta_caps))\n",
        "\n",
        "        # calculate gamma for cauchy kernel\n",
        "        gammas = torch.exp(1.0 - 2 * torch.abs(delta_caps))  # (B)\n",
        "\n",
        "        # coordinate of pixels on the glimpse\n",
        "        glimpse_pixels = Variable(torch.arange(0, glimpse_size) - (glimpse_size - 1.0) / 2.0)  # (glimpse_size)\n",
        "        if use_cuda:\n",
        "            glimpse_pixels = glimpse_pixels.cuda()\n",
        "\n",
        "        # space out with delta\n",
        "        glimpse_pixels = deltas[:, None] * glimpse_pixels[None, :]  # (B, glimpse_size)\n",
        "        # center around the centers\n",
        "        glimpse_pixels = centers[:, None] + glimpse_pixels  # (B, glimpse_size)\n",
        "\n",
        "        # coordinates of pixels on the image\n",
        "        image_pixels = Variable(torch.arange(0, image_size))  # (image_size)\n",
        "        if use_cuda:\n",
        "            image_pixels = image_pixels.cuda()\n",
        "\n",
        "        fx = image_pixels - glimpse_pixels[:, :, None]  # (B, glimpse_size, image_size)\n",
        "        fx = fx / gammas[:, None, None]\n",
        "        fx = fx ** 2.0\n",
        "        fx = 1.0 + fx\n",
        "        fx = math.pi * gammas[:, None, None] * fx\n",
        "        fx = 1.0 / fx\n",
        "        fx = fx / (torch.sum(fx, dim=2) + 1e-4)[:, :, None]  # we add a small constant in the denominator division by 0.\n",
        "\n",
        "        return fx.transpose(1, 2)\n",
        "\n",
        "    def get_attention_mask(self, glimpse_params: Variable, mask_h: int, mask_w: int) -> Variable:\n",
        "        \"\"\"\n",
        "        For visualization, generate a heat map (or mask) of which pixels got the most \"attention\".\n",
        "        Args:\n",
        "            glimpse_params (B, hx):  A batch of glimpse parameters.\n",
        "            mask_h (int): The height of the image for which the mask is being generated.\n",
        "            mask_w (int): The width of the image for which the mask is being generated.\n",
        "        Returns:\n",
        "            (B, mask_h, mask_w): A batch of masks with attended pixels weighted more.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, _ = glimpse_params.size()\n",
        "\n",
        "        # (B, image_h, glimpse_h)\n",
        "        F_h = self._get_filterbanks(delta_caps=glimpse_params[:, 2], center_caps=glimpse_params[:, 0],\n",
        "                                    image_size=mask_h, glimpse_size=self.glimpse_h)\n",
        "\n",
        "        # (B, image_w, glimpse_w)\n",
        "        F_w = self._get_filterbanks(delta_caps=glimpse_params[:, 2], center_caps=glimpse_params[:, 1],\n",
        "                                    image_size=mask_w, glimpse_size=self.glimpse_w)\n",
        "\n",
        "        # (B, glimpse_h, glimpse_w)\n",
        "        glimpse_proxy = Variable(torch.ones(batch_size, self.glimpse_h, self.glimpse_w))\n",
        "\n",
        "        # find the attention mask that lead to the glimpse.\n",
        "        mask = glimpse_proxy\n",
        "        mask = torch.bmm(F_h, mask)\n",
        "        mask = torch.bmm(mask, F_w.transpose(1, 2))\n",
        "\n",
        "        # scale to between 0 and 1.0\n",
        "        mask = mask - mask.min()\n",
        "        mask = mask / mask.max()\n",
        "        mask = mask.float()\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def get_glimpse(self, images: Variable, glimpse_params: Variable) -> Variable:\n",
        "        \"\"\"\n",
        "        Generate glimpses given images and glimpse parameters. This is the main method of this class.\n",
        "        The glimpse parameters are (h_center, w_center, delta). (h_center, w_center)\n",
        "        represents the relative position of the center of the glimpse on the image. delta determines\n",
        "        the zoom factor of the glimpse.\n",
        "        Args:\n",
        "            images (B, h, w):  A batch of images\n",
        "            glimpse_params (B, 3):  A batch of glimpse parameters (h_center, w_center, delta)\n",
        "        Returns:\n",
        "            (B, glimpse_h, glimpse_w): A batch of glimpses.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, image_h, image_w = images.size()\n",
        "\n",
        "        # (B, image_h, glimpse_h)\n",
        "        F_h = self._get_filterbanks(delta_caps=glimpse_params[:, 2], center_caps=glimpse_params[:, 0],\n",
        "                                    image_size=image_h, glimpse_size=self.glimpse_h)\n",
        "\n",
        "        # (B, image_w, glimpse_w)\n",
        "        F_w = self._get_filterbanks(delta_caps=glimpse_params[:, 2], center_caps=glimpse_params[:, 1],\n",
        "                                    image_size=image_w, glimpse_size=self.glimpse_w)\n",
        "\n",
        "        # F_h.T * images * F_w\n",
        "        glimpses = images\n",
        "        glimpses = torch.bmm(F_h.transpose(1, 2), glimpses)\n",
        "        glimpses = torch.bmm(glimpses, F_w)\n",
        "\n",
        "        return glimpses  # (B, glimpse_h, glimpse_w)\n",
        "\n",
        "\n",
        "class ARC(nn.Module):\n",
        "    \"\"\"\n",
        "    This class implements the Attentive Recurrent Comparators. This module has two main parts.\n",
        "    1.) controller: The RNN module that takes as input glimpses from a pair of images and emits a hidden state.\n",
        "    2.) glimpser: A Linear layer that takes the hidden state emitted by the controller and generates the glimpse\n",
        "                    parameters. These glimpse parameters are (h_center, w_center, delta). (h_center, w_center)\n",
        "                    represents the relative position of the center of the glimpse on the image. delta determines\n",
        "                    the zoom factor of the glimpse.\n",
        "    Args:\n",
        "        num_glimpses (int): How many glimpses must the ARC \"see\" before emitting the final hidden state.\n",
        "        glimpse_h (int): The height of the glimpse in pixels.\n",
        "        glimpse_w (int): The width of the glimpse in pixels.\n",
        "        controller_out (int): The size of the hidden state emitted by the controller.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_glimpses: int=8, glimpse_h: int=8, glimpse_w: int=8, controller_out: int=128) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_glimpses = num_glimpses\n",
        "        self.glimpse_h = glimpse_h\n",
        "        self.glimpse_w = glimpse_w\n",
        "        self.controller_out = controller_out\n",
        "\n",
        "        # main modules of ARC\n",
        "\n",
        "        self.controller = nn.LSTMCell(input_size=(glimpse_h * glimpse_w), hidden_size=self.controller_out)\n",
        "        self.glimpser = nn.Linear(in_features=self.controller_out, out_features=3)\n",
        "\n",
        "        # this will actually generate glimpses from images using the glimpse parameters.\n",
        "        self.glimpse_window = GlimpseWindow(glimpse_h=self.glimpse_h, glimpse_w=self.glimpse_w)\n",
        "\n",
        "    def forward(self, image_pairs: Variable) -> Variable:\n",
        "        \"\"\"\n",
        "        The method calls the internal _forward() method which returns hidden states for all time steps. This i\n",
        "        Args:\n",
        "            image_pairs (B, 2, h, w):  A batch of pairs of images\n",
        "        Returns:\n",
        "            (B, controller_out): A batch of final hidden states after each pair of image has been shown for num_glimpses\n",
        "            glimpses.\n",
        "        \"\"\"\n",
        "\n",
        "        # return only the last hidden state\n",
        "        all_hidden = self._forward(image_pairs)  # (2*num_glimpses, B, controller_out)\n",
        "        last_hidden = all_hidden[-1, :, :]  # (B, controller_out)\n",
        "\n",
        "        return last_hidden\n",
        "\n",
        "    def _forward(self, image_pairs: Variable) -> Variable:\n",
        "        \"\"\"\n",
        "        The main forward method of ARC. But it returns hidden state from all time steps (all glimpses) as opposed to\n",
        "        just the last one. See the exposed forward() method.\n",
        "        Args:\n",
        "            image_pairs: (B, 2, h, w) A batch of pairs of images\n",
        "        Returns:\n",
        "            (2*num_glimpses, B, controller_out) Hidden states from ALL time steps.\n",
        "        \"\"\"\n",
        "\n",
        "        # convert to images to float.\n",
        "        image_pairs = image_pairs.float()\n",
        "\n",
        "        # calculate the batch size\n",
        "        batch_size = image_pairs.size()[0]\n",
        "\n",
        "        # an array for collecting hidden states from each time step.\n",
        "        all_hidden = []\n",
        "\n",
        "        # initial hidden state of the LSTM.\n",
        "        Hx = Variable(torch.zeros(batch_size, self.controller_out))  # (B, controller_out)\n",
        "        Cx = Variable(torch.zeros(batch_size, self.controller_out))  # (B, controller_out)\n",
        "\n",
        "        if use_cuda:\n",
        "            Hx, Cx = Hx.cuda(), Cx.cuda()\n",
        "\n",
        "        # take `num_glimpses` glimpses for both images, alternatingly.\n",
        "        for turn in range(2*self.num_glimpses):\n",
        "            # select image to show, alternate between the first and second image in the pair\n",
        "            images_to_observe = image_pairs[:,  turn % 2]  # (B, h, w)\n",
        "\n",
        "            # choose a portion from image to glimpse using attention\n",
        "            glimpse_params = torch.tanh(self.glimpser(Hx))  # (B, 3)  a batch of glimpse params (x, y, delta)\n",
        "            glimpses = self.glimpse_window.get_glimpse(images_to_observe, glimpse_params)  # (B, glimpse_h, glimpse_w)\n",
        "            flattened_glimpses = glimpses.view(batch_size, -1)  # (B, glimpse_h * glimpse_w), one time-step\n",
        "\n",
        "            # feed the glimpses and the previous hidden state to the LSTM.\n",
        "            Hx, Cx = self.controller(flattened_glimpses, (Hx, Cx))  # (B, controller_out), (B, controller_out)\n",
        "\n",
        "            # append this hidden state to all states\n",
        "            all_hidden.append(Hx)\n",
        "\n",
        "        all_hidden = torch.stack(all_hidden)  # (2*num_glimpses, B, controller_out)\n",
        "\n",
        "        # return a batch of all hidden states.\n",
        "        return all_hidden\n",
        "\n",
        "\n",
        "class ArcBinaryClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A binary classifier that uses ARC.\n",
        "    Given a pair of images, feeds them the ARC and uses the final hidden state of ARC to\n",
        "    classify the images as belonging to the same class or not.\n",
        "    Args:\n",
        "        num_glimpses (int): How many glimpses must the ARC \"see\" before emitting the final hidden state.\n",
        "        glimpse_h (int): The height of the glimpse in pixels.\n",
        "        glimpse_w (int): The width of the glimpse in pixels.\n",
        "        controller_out (int): The size of the hidden state emitted by the controller.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_glimpses: int=8, glimpse_h: int=8, glimpse_w: int=8, controller_out: int = 128):\n",
        "        super().__init__()\n",
        "        self.arc = ARC(\n",
        "            num_glimpses=num_glimpses,\n",
        "            glimpse_h=glimpse_h,\n",
        "            glimpse_w=glimpse_w,\n",
        "            controller_out=controller_out)\n",
        "\n",
        "        # two dense layers, which take the hidden state from the controller of ARC and\n",
        "        # classify the images as belonging to the same class or not.\n",
        "        self.dense1 = nn.Linear(controller_out, 64)\n",
        "        self.dense2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, image_pairs: Variable) -> Variable:\n",
        "        arc_out = self.arc(image_pairs)\n",
        "\n",
        "        d1 = F.elu(self.dense1(arc_out))\n",
        "        decision = torch.sigmoid(self.dense2(d1))\n",
        "\n",
        "        return decision\n",
        "\n",
        "    def save_to_file(self, file_path: str) -> None:\n",
        "        torch.save(self.state_dict(), file_path)"
      ],
      "metadata": {
        "id": "FcJ4-Sjaz68G"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pct_accuracy(pred: Variable, target) -> int:\n",
        "    hard_pred = (pred > 0.5).int()\n",
        "    correct = (hard_pred == target).sum().data[0]\n",
        "    accuracy = float(correct) / target.size()[0]\n",
        "    accuracy = int(accuracy * 100)\n",
        "    return accuracy\n",
        "\n",
        "def train():\n",
        "  discriminator =\\\n",
        "    ArcBinaryClassifier(\n",
        "        num_glimpses = 6, \n",
        "        glimpse_h = 8, \n",
        "        glimpse_w = 8,\n",
        "        controller_out = 128\n",
        "        )\n",
        "  bce = torch.nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(params=discriminator.parameters(), lr = 0.0002)\n",
        "  loader = Batcher(batch_size = 100, image_size = 32)\n",
        "\n",
        "  best_validation_loss = None\n",
        "  saving_threshold = 1.02\n",
        "  last_saved = datetime.utcnow()\n",
        "  save_every = timedelta(minutes=10)\n",
        "\n",
        "  i = -1\n",
        "  while True:\n",
        "      i += 1\n",
        "\n",
        "      X, Y = loader.fetch_batch(\"train\")\n",
        "      pred = discriminator(X)\n",
        "      loss = bce(pred, Y.float())\n",
        "\n",
        "      if i % 10 == 0:\n",
        "\n",
        "          # validate your model\n",
        "          X_val, Y_val = loader.fetch_batch(\"val\")\n",
        "          pred_val = discriminator(X_val)\n",
        "          loss_val = bce(pred_val, Y_val.float())\n",
        "\n",
        "          training_loss = loss.data[0]\n",
        "          validation_loss = loss_val.data[0]\n",
        "\n",
        "          print(\"Iteration: {} \\t Train: Acc={}%, Loss={} \\t\\t Validation: Acc={}%, Loss={}\".format(\n",
        "              i, get_pct_accuracy(pred, Y), training_loss, get_pct_accuracy(pred_val, Y_val), validation_loss\n",
        "          ))\n",
        "\n",
        "          if best_validation_loss is None:\n",
        "              best_validation_loss = validation_loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    train()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "xuuEBk8-CJgW",
        "outputId": "e8d17f8b-5157-48f1-bfbf-981d65ad76bd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-2ddc357d8855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-2ddc357d8855>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-2ddc357d8855>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mbest_validation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-e32be7841482>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch_size, image_size)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmniglot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'omniglot.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mOmniglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0ma_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-e32be7841482>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch_size, image_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1623\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mresized_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresized_chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resize' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batchSize', type=int, default=128, help = 100)\n",
        "parser.add_argument('--imageSize', type=int, default=32, help = (480,480))\n",
        "parser.add_argument('--glimpseSize', type=int, default=8, help='the height / width of glimpse seen by ARC')\n",
        "parser.add_argument('--numStates', type=int, default=128, help='number of hidden states in ARC controller')\n",
        "parser.add_argument('--numGlimpses', type=int, default=6, help='the number glimpses of each image in pair seen by ARC')\n",
        "#parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
        "parser.add_argument('--name', default=None, help='Custom name for this configuration. Needed for saving' ' model checkpoints in a separate folder.')\n",
        "parser.add_argument('--load', default=None, help='the model to load from. Start fresh if not specified.')\n",
        "\n",
        "\n",
        "#def get_pct_accuracy(pred: Variable, target) -> int:\n",
        "#    hard_pred = (pred > 0.5).int()\n",
        "#    correct = (hard_pred == target).sum().data[0]\n",
        "#    accuracy = float(correct) / target.size()[0]\n",
        "#    accuracy = int(accuracy * 100)\n",
        "#    return accuracy\n",
        "\n",
        "\n",
        "def train():\n",
        "#    opt = parser.parse_args()\n",
        "\n",
        "#    if opt.cuda:\n",
        "#        batcher.use_cuda = True\n",
        "#        models.use_cuda = True\n",
        "\n",
        "#    if opt.name is None:\n",
        "        # if no name is given, we generate a name from the parameters.\n",
        "        # only those parameters are taken, which if changed break torch.load compatibility.\n",
        "#        opt.name = \"{}_{}_{}_{}\".format(opt.numGlimpses, opt.glimpseSize, opt.numStates, \"cuda\" if opt.cuda else \"cpu\")\n",
        "\n",
        "    print(\"Will start training {} with parameters:\\n{}\\n\\n\".format(opt.name, opt))\n",
        "\n",
        "    # make directory for storing models.\n",
        "    models_path = os.path.join(\"saved_models\", opt.name)\n",
        "    os.makedirs(models_path, exist_ok=True)\n",
        "\n",
        "    # initialise the model\n",
        "    discriminator = ArcBinaryClassifier(num_glimpses=opt.numGlimpses, glimpse_h=opt.glimpseSize, glimpse_w=opt.glimpseSize,controller_out=opt.numStates)\n",
        "\n",
        "    if opt.cuda:\n",
        "        discriminator.cuda()\n",
        "\n",
        "    # load from a previous checkpoint, if specified.\n",
        "    if opt.load is not None:\n",
        "        discriminator.load_state_dict(torch.load(os.path.join(models_path, opt.load)))\n",
        "\n",
        "    # set up the optimizer.\n",
        "    bce = torch.nn.BCELoss()\n",
        "    #if opt.cuda:\n",
        "    #    bce = bce.cuda()\n",
        "\n",
        "    #optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=opt.lr)\n",
        "    optimizer = torch.optim.Adam(params=discriminator.parameters(), lr = 0.0002)\n",
        "\n",
        "    # load the dataset in memory.\n",
        "    #loader = Batcher(batch_size=opt.batchSize, image_size=opt.imageSize)\n",
        "    loader = Batcher(batch_size=opt.batchSize, image_size=opt.imageSize)\n",
        "\n",
        "    # ready to train ...\n",
        "    best_validation_loss = None\n",
        "    saving_threshold = 1.02\n",
        "    last_saved = datetime.utcnow()\n",
        "    save_every = timedelta(minutes=10)\n",
        "\n",
        "    i = -1\n",
        "    while True:\n",
        "        i += 1\n",
        "\n",
        "        X, Y = loader.fetch_batch(\"train\")\n",
        "        pred = discriminator(X)\n",
        "        loss = bce(pred, Y.float())\n",
        "\n",
        "        if i % 10 == 0:\n",
        "\n",
        "            # validate your model\n",
        "            X_val, Y_val = loader.fetch_batch(\"val\")\n",
        "            pred_val = discriminator(X_val)\n",
        "            loss_val = bce(pred_val, Y_val.float())\n",
        "\n",
        "            training_loss = loss.data[0]\n",
        "            validation_loss = loss_val.data[0]\n",
        "\n",
        "            print(\"Iteration: {} \\t Train: Acc={}%, Loss={} \\t\\t Validation: Acc={}%, Loss={}\".format(\n",
        "                i, get_pct_accuracy(pred, Y), training_loss, get_pct_accuracy(pred_val, Y_val), validation_loss\n",
        "            ))\n",
        "\n",
        "            if best_validation_loss is None:\n",
        "                best_validation_loss = validation_loss\n",
        "\n",
        "            if best_validation_loss > (saving_threshold * validation_loss):\n",
        "                print(\"Significantly improved validation loss from {} --> {}. Saving...\".format(\n",
        "                    best_validation_loss, validation_loss\n",
        "                ))\n",
        "                discriminator.save_to_file(os.path.join(models_path, str(validation_loss)))\n",
        "                best_validation_loss = validation_loss\n",
        "                last_saved = datetime.utcnow()\n",
        "\n",
        "            if last_saved + save_every < datetime.utcnow():\n",
        "                print(\"It's been too long since we last saved the model. Saving...\")\n",
        "                discriminator.save_to_file(os.path.join(models_path, str(validation_loss)))\n",
        "                last_saved = datetime.utcnow()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    train()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "AoDZrl2d0BJU",
        "outputId": "978371a4-866e-4061-c376-96253657a3c9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--batchSize BATCHSIZE]\n",
            "                             [--imageSize IMAGESIZE]\n",
            "                             [--glimpseSize GLIMPSESIZE]\n",
            "                             [--numStates NUMSTATES]\n",
            "                             [--numGlimpses NUMGLIMPSES] [--lr LR] [--cuda]\n",
            "                             [--name NAME] [--load LOAD]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-976a4aee-7918-4194-89fe-b2ce110fbd3b.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batchSize', type=int, default=128, help='input batch size')\n",
        "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to ARC')\n",
        "parser.add_argument('--glimpseSize', type=int, default=8, help='the height / width of glimpse seen by ARC')\n",
        "parser.add_argument('--numStates', type=int, default=128, help='number of hidden states in ARC controller')\n",
        "parser.add_argument('--numGlimpses', type=int, default=6, help='the number glimpses of each image in pair seen by ARC')\n",
        "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
        "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
        "parser.add_argument('--name', default=None, help='Custom name for this configuration. Needed for loading model'\n",
        "                                                 'and saving images')\n",
        "parser.add_argument('--load', required=True, help='the model to load from.')\n",
        "parser.add_argument('--same', action='store_true', help='whether to generate same character pairs or not')\n",
        "\n",
        "opt = parser.parse_args()\n",
        "\n",
        "if opt.name is None:\n",
        "    # if no name is given, we generate a name from the parameters.\n",
        "    # only those parameters are taken, which if changed break torch.load compatibility.\n",
        "    opt.name = \"{}_{}_{}_{}\".format(opt.numGlimpses, opt.glimpseSize, opt.numStates,\n",
        "                                    \"cuda\" if opt.cuda else \"cpu\")\n",
        "\n",
        "# make directory for storing images.\n",
        "images_path = os.path.join(\"visualization\", opt.name)\n",
        "os.makedirs(images_path, exist_ok=True)\n",
        "\n",
        "\n",
        "# initialise the batcher\n",
        "batcher = Batcher(batch_size=opt.batchSize)\n",
        "\n",
        "\n",
        "def display(image1, mask1, image2, mask2, name=\"hola.png\"):\n",
        "    _, ax = plt.subplots(1, 2)\n",
        "\n",
        "    # a heuristic for deciding cutoff\n",
        "    masking_cutoff = 2.4 / (opt.glimpseSize)**2\n",
        "\n",
        "    mask1 = (mask1 > masking_cutoff).data.numpy()\n",
        "    mask1 = np.ma.masked_where(mask1 == 0, mask1)\n",
        "\n",
        "    mask2 = (mask2 > masking_cutoff).data.numpy()\n",
        "    mask2 = np.ma.masked_where(mask2 == 0, mask2)\n",
        "\n",
        "    ax[0].imshow(image1.data.numpy(), cmap=mpl.cm.bone)\n",
        "    ax[0].imshow(mask1, interpolation=\"nearest\", cmap=mpl.cm.jet_r, alpha=0.7)\n",
        "\n",
        "    ax[1].imshow(image2.data.numpy(), cmap=mpl.cm.bone)\n",
        "    ax[1].imshow(mask2, interpolation=\"nearest\", cmap=mpl.cm.ocean, alpha=0.7)\n",
        "\n",
        "    plt.savefig(os.path.join(images_path, name))\n",
        "\n",
        "\n",
        "def get_sample(discriminator):\n",
        "\n",
        "    # size of the set to choose sample from from\n",
        "    sample_size = 30\n",
        "    X, Y = batcher.fetch_batch(\"train\", batch_size=sample_size)\n",
        "    pred = discriminator(X)\n",
        "\n",
        "    if opt.same:\n",
        "        same_pred = pred[sample_size // 2:].data.numpy()[:, 0]\n",
        "        mx = same_pred.argsort()[len(same_pred) // 2]  # choose the sample with median confidence\n",
        "        index = mx + sample_size // 2\n",
        "    else:\n",
        "        diff_pred = pred[:sample_size // 2].data.numpy()[:, 0]\n",
        "        mx = diff_pred.argsort()[len(diff_pred) // 2]  # choose the sample with median confidence\n",
        "        index = mx\n",
        "\n",
        "    return X[index]\n",
        "\n",
        "\n",
        "def visualize():\n",
        "\n",
        "    # initialise the model\n",
        "    discriminator = ArcBinaryClassifier(num_glimpses=opt.numGlimpses,\n",
        "                                        glimpse_h=opt.glimpseSize,\n",
        "                                        glimpse_w=opt.glimpseSize,\n",
        "                                        controller_out=opt.numStates)\n",
        "    discriminator.load_state_dict(torch.load(os.path.join(\"saved_models\", opt.name, opt.load)))\n",
        "\n",
        "    arc = discriminator.arc\n",
        "\n",
        "    sample = get_sample(discriminator)\n",
        "\n",
        "    all_hidden = arc._forward(sample[None, :, :])[:, 0, :]  # (2*numGlimpses, controller_out)\n",
        "    glimpse_params = torch.tanh(arc.glimpser(all_hidden))\n",
        "    masks = arc.glimpse_window.get_attention_mask(glimpse_params, mask_h=opt.imageSize, mask_w=opt.imageSize)\n",
        "\n",
        "    # separate the masks of each image.\n",
        "    masks1 = []\n",
        "    masks2 = []\n",
        "    for i, mask in enumerate(masks):\n",
        "        if i % 2 == 1:  # the first image outputs the hidden state for the next image\n",
        "            masks1.append(mask)\n",
        "        else:\n",
        "            masks2.append(mask)\n",
        "\n",
        "    for i, (mask1, mask2) in enumerate(zip(masks1, masks2)):\n",
        "        display(sample[0], mask1, sample[1], mask2, \"img_{}\".format(i))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "4rTEwyMW0F4x",
        "outputId": "e2e375a5-496b-4eeb-e101-1bf69bebda4b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--batchSize BATCHSIZE]\n",
            "                             [--imageSize IMAGESIZE]\n",
            "                             [--glimpseSize GLIMPSESIZE]\n",
            "                             [--numStates NUMSTATES]\n",
            "                             [--numGlimpses NUMGLIMPSES] [--lr LR] [--cuda]\n",
            "                             [--name NAME] --load LOAD [--same]\n",
            "ipykernel_launcher.py: error: the following arguments are required: --load\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKd_cBPH0KZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}