{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpNWjgI32Ph61fYk8NQf3Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhayb-h/Acute-Lymphoblastic-Leukemia-Classifier/blob/main/New_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final notebook outlines building a transfer learning neural network to identify lymphoblasts as being cancerous or normal.\n",
        "\n",
        "Transfer learning requires a pre-trained neural network to serve as a starting point in model construction. In the context of image classification, a ready-made model trained on a large and generalized dataset will serve as a generic model of the visual world. New layers can be added to the base model and only these new layers will be trained towards the specified task of interest. In the case of this project, the task is to correctly identify images in the ISBI-2019 dataset as cancerous or normal. As an analogy, the machine needs to be 'specialized' much like physicians, clinicians and scientists need to specialize their knowledge of the entire visual world towards interpreting images of cells and microscopic features.\n",
        "\n",
        "A pre-trained image classifier model is a documented and openly available network that was previously trained on a extensive dataset of random images. For this project, a pre-trained model will be used directly from TensorFlow Hub, a repository of pre-trained TensorFlow models. Once a model has been loaded, new layers were added to allow for transfer learning to fine-tune the model to serve as an ALL classifier model.\n",
        "\n",
        "There are two ways to customize the pre-trained model:\n",
        "\n",
        "*   Feature Extraction: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for the dataset.\n",
        "\n",
        "*   Fine-Tuning: Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine-tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n",
        "Data augmentation serves as a central principal that will be applied to all models in this project. The purpose of this practice was to increase the diversity of the training set by applying random, yet realistic, transformations to the dataset to create new images for the dataset. These transformations include image flipping and image rotation."
      ],
      "metadata": {
        "id": "l80YLJTRRheu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compose the model\n",
        "\n",
        "*   Load in the pretrained base model and corresponding pretrained weights\n",
        "*   Stack the classification layers on top"
      ],
      "metadata": {
        "id": "dLUVAy4lSLqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KSJldYPTa9UO",
        "outputId": "01156a7a-c0b1-4ca7-aeb9-5c5816db440b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow hub has a variety of models available to be used for a variety of purposes. 154 models are available within this repository for image classification alone. When selecting for models trained on the largest possible generalized dataset (identified as the ImageNet ILSVRC dataset) and the most recent version of the TensorFlow library, 65 models were available. Of the myriad of model architectures available, the most complex and latest variant ResNet model was selected as the pre-trained model to be used for the ALL classifier. This model is the ResNet V2 152 model."
      ],
      "metadata": {
        "id": "QgnQaYYpakS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base = \"https://tfhub.dev/google/imagenet/resnet_v2_152/classification/5\"\n",
        "\n",
        "classifier_base = \\\n",
        "  hub.KerasLayer(\n",
        "      resnet_base, \n",
        "      input_shape = (480, 480, 3),\n",
        "      trainable = False #Training base model won't yield significant improvements\n",
        "      )"
      ],
      "metadata": {
        "id": "dJgrTPx8gHn4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  str('/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/training_data'),\n",
        "  validation_split = 0.175,\n",
        "  labels = 'inferred',\n",
        "  label_mode = 'categorical',\n",
        "  class_names = ('hem', 'all'),\n",
        "  color_mode = 'rgb',\n",
        "  shuffle = True,\n",
        "  subset = \"training\",\n",
        "  seed = 42,\n",
        "  image_size = (480, 480),\n",
        "  batch_size = 100\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  str('/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/training_data'),\n",
        "  validation_split = 0.175,\n",
        "  labels = 'inferred',\n",
        "  label_mode = 'categorical',\n",
        "  class_names = ('hem', 'all'),\n",
        "  color_mode = 'rgb',\n",
        "  shuffle = True,\n",
        "  subset = \"validation\",\n",
        "  seed = 42,\n",
        "  image_size = (480, 480),\n",
        "  batch_size = 100\n",
        ")"
      ],
      "metadata": {
        "id": "TDdFHMOLiOr2",
        "outputId": "9a3e62e4-ff39-457b-eec0-d88a7b18503e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10661 files belonging to 2 classes.\n",
            "Using 8796 files for training.\n",
            "Found 10661 files belonging to 2 classes.\n",
            "Using 1865 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.class_names"
      ],
      "metadata": {
        "id": "BzmMHG7pir8H",
        "outputId": "482773a5-606f-49eb-ce98-44f66eb88d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hem', 'all')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
      ],
      "metadata": {
        "id": "GTvCvzKUirz6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight calculation for normal lymphocytes:  \n",
        "# Number of cancer cells divided by the number of normal cells.\n",
        "\n",
        "7272/3389"
      ],
      "metadata": {
        "id": "EXe4-qwVncey",
        "outputId": "4a910321-e9f9-454c-9ca0-aec45c265061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.145765712599587"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight of 2.15 is applied to 'hem' cells\n",
        "\n",
        "weights = {0: 2.15,\n",
        "           1: 1}"
      ],
      "metadata": {
        "id": "9xADgeb-nbki"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell ensures the GPU is working optimally by ensuring data is delivered for the next step before the current step has finished\n",
        "#AUTOTUNE = tf.data.AUTOTUNE\n",
        "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "WH-fqp8RirwP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for image_batch, labels_batch in train_ds:\n",
        "#  print(image_batch.shape)\n",
        "#  print(labels_batch.shape)\n",
        "#  break"
      ],
      "metadata": {
        "id": "UHtr1VdMyvs_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_batch = classifier(image_batch)\n",
        "#print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "B-_4J4Oxirq5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  classifier_base,\n",
        "  tf.keras.layers.Dense(2) #Narrows the model to either 'all' or 'hem'\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer = tf.keras.optimizers.Adam(),\n",
        "  loss = 'CategoricalCrossentropy',\n",
        "  metrics = 'CategoricalAccuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3_ZzivE43C2n",
        "outputId": "fbd66aff-0309-4ec4-f3dc-6027c8275b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1001)              60382697  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2004      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,384,701\n",
            "Trainable params: 2,004\n",
            "Non-trainable params: 60,382,697\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n"
      ],
      "metadata": {
        "id": "F8Il-F6_SLX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model(image_batch)\n",
        "#predictions.shape"
      ],
      "metadata": {
        "id": "znotEiRL3Czv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#%tensorboard --logdir logs/fit\n",
        "\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "#    log_dir = log_dir,\n",
        "#    histogram_freq = 1) # Enable histogram computation for every epoch\n",
        "\n",
        "model_2 = model.fit(train_ds, \n",
        "                    validation_data = val_ds, \n",
        "                    epochs = 25, \n",
        "                    class_weight = weights)\n",
        "#                    callbacks = tensorboard_callback)\n",
        "model_2_df = pd.DataFrame(model_2.history)\n",
        "path_2 =\\\n",
        "'/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/training_data/model_2.csv'\n",
        "\n",
        "with open(path_2, 'w', encoding = 'utf-8-sig') as f:\n",
        "  model_2_df.to_csv(f)"
      ],
      "metadata": {
        "id": "CHyFk8e-3CxI",
        "outputId": "66fc36e9-19bf-4986-f601-9a963bfbf0f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "88/88 [==============================] - 194s 2s/step - loss: 1.1105 - categorical_accuracy: 0.5375 - val_loss: 0.6800 - val_categorical_accuracy: 0.5239\n",
            "Epoch 2/25\n",
            "88/88 [==============================] - 163s 2s/step - loss: 0.7966 - categorical_accuracy: 0.6958 - val_loss: 0.5909 - val_categorical_accuracy: 0.7823\n",
            "Epoch 3/25\n",
            "88/88 [==============================] - ETA: 0s - loss: 0.7829 - categorical_accuracy: 0.7922"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_df = \\\n",
        "pd.read_csv(\n",
        "'/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/training_data/model_2.csv')\n",
        "model_2_df"
      ],
      "metadata": {
        "id": "SlWBixKNLbHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (15,7))\n",
        "\n",
        "plt.subplot(1, 2, 1, title = 'Loss')\n",
        "plt.plot(model_2_df['loss'], \n",
        "         color = 'teal', \n",
        "         label = 'loss')\n",
        "plt.plot(model_2['val_loss'], \n",
        "         color = 'orange', \n",
        "         label = 'val_loss')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.subplot(1, 2, 2, title = 'Accuracy')\n",
        "plt.plot(model_2_df['acc'], \n",
        "         color = 'teal', \n",
        "         label = 'accuracy')\n",
        "plt.plot(model_2_df['val_acc'], \n",
        "         color = 'orange', \n",
        "         label = 'val_accuracy')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "#plt.subplots_adjust(wspace=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iAcwyfsvSKSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate model"
      ],
      "metadata": {
        "id": "2D03REJ1SLOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = \\\n",
        "pd.read_csv(\n",
        "    '/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv', \n",
        "    dtype = str)\n",
        "\n",
        "# a new column called labels_ was created wherein 'all' patients are labelled 0 \n",
        "#df_test.loc[df_test['Patient_ID'].str.contains('all'), 'true_labels'] = '0'\n",
        "\n",
        "# labels_ was also given a label 1 for any patients that were non-cancerous\n",
        "#df_test.loc[df_test['Patient_ID'].str.contains('hem'), 'true_labels'] = '1'\n",
        "\n",
        "df_test"
      ],
      "metadata": {
        "id": "ES8KT21Ot_Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = \\\n",
        "test_datagen.flow_from_dataframe(\n",
        "    dataframe = df_test,\n",
        "    directory = \\\n",
        "    '/content/drive/Othercomputers/My MacBook Air/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data',\n",
        "    batch_size = 100,\n",
        "    x_col = val_ds.class_names,\n",
        "    y_col = 'true_labels',\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "X_test, y_test = test_generator.next()"
      ],
      "metadata": {
        "id": "z2dXWv9xuJ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_2 = model_2.evaluate(X_test, y_test)\n",
        "score_2\n",
        "#print('Test loss:', score_2[0])\n",
        "#print('Test accuracy:', score_2[1])"
      ],
      "metadata": {
        "id": "eDLXeTdLvSUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the predictions\n",
        "predict_probas_2 = model_2.predict(X_test) \n",
        "\n",
        "# Convert probabilities to label encoding\n",
        "y_predict_2 = np.argmax(predict_probas_2, axis=1)"
      ],
      "metadata": {
        "id": "OVTsgCIrvsUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "conf_mat_2 = confusion_matrix(y_test_labels, y_predict_2)\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "sns.heatmap(conf_mat_2,\n",
        "            annot=True,\n",
        "            cbar=False,\n",
        "            xticklabels = val_ds.class_names,\n",
        "            yticklabels = val_ds.class_names,\n",
        "            cmap = \"rocket_r\",\n",
        "            linewidths = 1)\n",
        "plt.title('Confusion Matrix for Sequential CNN', \n",
        "          size = 25, \n",
        "          y = 1.01)\n",
        "plt.xlabel(\"Predicted Label\", size = 20)\n",
        "plt.ylabel(\"True Label\", size = 20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TBd-7G6Jvumn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}